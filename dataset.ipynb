{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.util import filter_spans\n",
    "from spacy.tokens import DocBin, Doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset ade_corpus_v2 (C:/Users/hamel/.cache/huggingface/datasets/ade_corpus_v2/Ade_corpus_v2_drug_ade_relation/1.0.0/940d61334dbfac6b01ac5d00286a2122608b8dc79706ee7e9206a1edb172c559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19517e1af26a4ba4b0c13c4cba943150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ade_corpus_v2\",'Ade_corpus_v2_drug_ade_relation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'drug', 'effect', 'indexes'],\n",
      "        num_rows: 6821\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Intravenous azithromycin-induced ototoxicity.',\n",
       " 'drug': 'azithromycin',\n",
       " 'effect': 'ototoxicity',\n",
       " 'indexes': {'drug': {'start_char': [12], 'end_char': [24]},\n",
       "  'effect': {'start_char': [33], 'end_char': [44]}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = {}\n",
    "\n",
    "for row in dataset['train']:\n",
    "    start_drug = row[\"indexes\"][\"drug\"][\"start_char\"]\n",
    "    end_drug = row[\"indexes\"][\"drug\"][\"end_char\"]\n",
    "    start_effect = row[\"indexes\"][\"effect\"][\"start_char\"]\n",
    "    end_effect = row[\"indexes\"][\"effect\"][\"end_char\"]\n",
    "    if row['text'] not in training_dataset:\n",
    "        training_dataset[row['text']] = {}\n",
    "        training_dataset[row['text']]['entities'] = set()\n",
    "    \n",
    "    for i,drug_start_index in enumerate(start_drug):\n",
    "        training_dataset[row['text']]['entities'].add((start_drug[i], end_drug[i], \"DRUG\"))\n",
    "    for i,effect_start_index in enumerate(start_effect):\n",
    "        training_dataset[row['text']]['entities'].add((start_effect[i], end_effect[i], \"REACTION\"))\n",
    "        \n",
    "                                                            \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dictionary to list of dictionaries\n",
    "training_dataset = [{'text': key, 'entities': list(value['entities'])} for key, value in training_dataset.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Intravenous azithromycin-induced ototoxicity.',\n",
       " 'entities': [(12, 24, 'DRUG'), (33, 44, 'REACTION')]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find longest text in the dataset in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_doc_format(row):\n",
    "    text = row['text']\n",
    "    annotations = row['entities']\n",
    "    \n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "    \n",
    "    #Remove text key from row\n",
    "    gold_dict = row.copy()\n",
    "    del gold_dict[\"text\"]\n",
    "\n",
    "    #example = Example.from_dict(doc, gold_dict)\n",
    "    for start, end, label in gold_dict[\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"expand\")\n",
    "        if span is None:\n",
    "            print(start, end, label)\n",
    "            print(doc.text[start:end])\n",
    "            print(text)\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    filtered_ents = filter_spans(ents)\n",
    "    doc.ents = filtered_ents \n",
    "    \n",
    "    return(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for row in training_dataset:\n",
    "    docs.append(to_doc_format(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "for doc in docs :\n",
    "    lenght = len([token.text for token in doc])\n",
    "    if lenght > max:\n",
    "        max = lenght\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mix the data randomly\n",
    "np.random.shuffle(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(0.8 * len(docs))\n",
    "\n",
    "TRAIN_DATA = docs[:split_index]\n",
    "TEST_DATA = docs[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bin = DocBin(docs=TRAIN_DATA)\n",
    "test_bin = DocBin(docs=TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bin.to_disk(\"train.spacy\")\n",
    "test_bin.to_disk(\"test.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Auto-filled config with all values\n",
      "✔ Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
